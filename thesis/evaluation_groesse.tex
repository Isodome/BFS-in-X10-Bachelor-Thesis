%!TEX root = thesis.tex
\subsection{Größe} % (fold)
\label{sub:gr_e}
Die Testreihe, um die Auswirkung der Größe eines Graphen auf die Algorithmen herauszufinden, orientiert sich an einem Socialgraph. Es wurde geschätz, dass jeder durchschnittlich 100 Freunde hat, jeder mehr als einen Freund hat und keiner mehr als 500 Freunde hat. Das ergibt einen durchschnittlichen Knotengrad von 100, wobei der Knotengrad zwischen 1 und 500 liegt. Variiert wurde nun die Größe der Graphen. Es handelt sich hier um relativ dünn besetzte Graphen, so dass selbst der 500 000 Knoten Graph noch unter 500 MB liegt. Es wurde versucht, die Graphgröße weiter auf bis zu 2 Millionen Knoten zu steigern, was allerdings nicht möglich war. Graphen mit vielen Knoten resultieren in großen Sendepuffern und wie sich herausstellte, ist X10 dem nicht gewachsen. Der Sendevorgang (der \textit{at} Block) wird in den meisten fällen nie verlassen. Deswegen wurde hier die Knotenzahl auf 500 000 beschränkt. Es ist zu vermuten, dass diese Größe nicht ausreicht, um gute Ergebnisse bei der Parallelisierung zu erreichen.

Des weiteren wurde in dieser Testreihe der Modus mit 9 Places und der invasive Algorithmus weggelassen. Dass mit 9 Places auf 8 Kernen die Performance nicht gut sein wird, war bereits zu erwarten und bestätigte sich. Der invasive Algorithmus hatte ebenso Probleme mit der Graphgröße, was zwar durch Implementierungstricks umgangen werden könnte, aber allerdings den Zeitrahmen gesprengt hätte. Wieso der invasive Algorithmus nicht funktioniert, ist in der Bemerkung unten erläutert.

Bei jedem Graph dieser Testreihe war die serielle Version am schnellsten, was nach den vorangegangenen Ergebnissen auf keinen Fall zu erwarten war. Die serielle Version war schneller als jeder andere Algorithmus, egal mit wie vielen Places. Im Kapitel \ref{sub:dichte}, in dem die Dichte variierte, war der 1D-Algorithmus schon im Fall mit nur einem Place schneller, als der serielle Algorithmus. Da das hier nicht auftritt, ist zu vermuten, dass der 1D Algorithmus für dichte Graphen ein wenig schneller zu sein scheint, während der serielle Algorithmus für dünn besetzte Graphen schneller ist.
% TODO: Begründung? 

Vergleicht man nur den 1D-Algorithmus mit sich selbst bei steigender Anzahl an Places, zeichnet sich das Bild, dass 2 Places das Maximum zu sein scheint. In Abbilgun \ref{fig:groesse_speedup} ist sehr schön zu sehen, dass der Algorithmus mit 2 Places immer schneller war, als der Algorithmus mit 4 Places. Bei 8 Places war der Speedup immer kleiner als 1, was langsamere Laufzeit als die Referenzzeit bedeutet. Wie zu erwarten steigt tendenziell mit der Anzahl der Knoten das Parallelisierungspotential, wobei es durch den dünn besetzte Graph einigermaßen beschränkt zu sein scheint. Wäre dem nicht so müsste der Algorithmus auf 4 Places gegenüber den 2 Places aufholen, bei steigender Knotenzahl.

Für den 2D Algorithmus gilt, dass nie ein Speedup kleiner 1 erreicht wurde. Die hier verwendeten Graphen sind dafür zu klein.

\begin{figure}
	\centering
	\label{fig:groesse_speedup}
	\caption{Speedup des 1D-Algorithmus über Anzahl der Places. Als Referenzwert wurde jeweils der 1D-Algorithmus mit einem Place genommen. Eine Kurve pro Graph.}
	\begin{tikzpicture}
		\begin{axis}[
	        xlabel=Parallelität,
	        ylabel=Speedup,
	        width=450, height=500]

		    \addplot+[
		    blue,
		    solid,
		    mark=*]
		    coordinates {
		        (1,1)
		        (2,0.818)
		        (4,0.6)
		        (8,0.141)
		    };
		    \addlegendentry{10k Knoten}

		    \addplot+[
		    red,
		    solid,
		    mark=x]
		    coordinates {
		        (1,1)
		        (2,1.106)
		        (4,1.04)
		        (8,0.531)
		    };
		    \addlegendentry{100k Knoten}

		    \addplot+[
		    green,
		    solid,
		    mark=+]
		    coordinates {
		        (1,1)
		        (2,1.277)
		        (4,0.974)
		        (8,0.699)
		    };
		    \addlegendentry{200k Knoten}

		    \addplot+[
		    brown,
		    solid,
		    mark=oplus]
		    coordinates {
		        (1,1)
		        (2,1.330)
		        (4,0.973)
		        (8,0.785)
		    };
		    \addlegendentry{300k Knoten}

		    \addplot+[
		    magenta,
		    solid,
		    mark=square*]
		    coordinates {
		        (1,1)
		        (2,1.331)
		        (4,1.217)
		        (8,0.82)
		    };
		    \addlegendentry{400k Knoten}

		    \addplot+[
		    orange,
		    solid,
		    mark=triangle]
		    coordinates {
		        (1,1)
		        (2,1.25)
		        (4,1.16)
		        (8,0.916)
		    };
		    \addlegendentry{500k Knoten}

		    \addplot+[
		        smooth,
		        dashed,
		        black,
		        mark=none]
		    coordinates {
		    	(0,1)
		    	(8,1)
		    };

		\end{axis}
	\end{tikzpicture}
\end{figure}

\underline{Bemerkung:}
Beim Parsen der Graphdatei gehen alle Implementierungen so vor, dass sie Zeile für Zeile in die Datenstruktur eingepflegt werden. Dabei steht schon vor dem Parsen fest, welches Datum auf welchen Place muss. Die Informationshäppchen, die von Place zu Place übertragen werden müssen, sind relativ klein. Im invasiven Fall ergibt es wenig Sinn, schon ein \textit{invade} aufzurufen, bevor überhaupt der Graph eingelesen wurde, bevor also die Größe des Problems bekannt ist. Aus diesem Grund wird der Graph erst lokal auf den ersten Place eingelesen, dann der Constraint zusammengebaut und erst wenn der Claim bekannt ist, auf die involvierten Places verteilt. Die hier zu übetragenen Daten sind relativ groß, womit X10 Probleme zu haben scheint. Das Problem könnte umgangen werden, indem die Datenstruktur in kleinere Häppchen aufgeteilt wird. Das ist aber höchstens ein Workaround um ein Problem, das bei X10 liegt.
% subsection gr_e (end)