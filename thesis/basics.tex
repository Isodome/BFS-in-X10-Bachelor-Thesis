%!TEX root = thesis.tex
\chapter{Grundlagen} % (fold)
\label{cha:grundlagen}

\section{Die Programmiersprache X10} % (fold)
\label{sec:die_programmiersprache_x10}
Die Programmiersprache X10 wird seit 2004 am IBM T. J. Watson Research Center bei New York in Kooperation mit einigen Universitäten entwickelt und gepflegt. X10 ist eine stark und statisch typisierte, objektorientierte Programmiersprache ohne Mehrfachvererbung. Was sequentielles Programmieren betrifft, entspricht die Feature-Liste weitgehend denen, die von anderen modernen objektorientierten Sprache bekannt sind. Nach Aussage der Entwickler ist X10 im Moment vor allem noch ein Forschungsobjekt und noch nicht für den Produktiveinsatz geeignet. Das Forschungs- und Entwicklungsziel von X10 ist es, eine Abstraktion von paralleler Programmierung zu finden, die es dem Entwickler erlaubt produktiver zu sein, als es mit traditionelleren Sprachen wie Java möglich wäre. Dazu wurden der Programmiersprache Konstrukte hinzugefügt, die einen impliziteren Umgang mit Parallelismus erlauben. Das Programmiermodell folgt dem PGAS (Partitioned Global Address Space) Speichermodel. Die drei für das Verständnis wichtigsten Aspekte von X10 sollen hier kurz beschrieben werden.\cite{x10FAQ:2012:Online}

\subsection{Activities und das Keyword \textit{async}}  % (fold)
\label{sub:aktivitaeten_und_das_keyword_async}
Das Konzept der \textit{Activity} in X10 ist dem der Threads sehr ähnlich. Eine Activity hat einen Programmzähler, einen eigenen Stack und ist semantisch nebenläufig zu allen anderen Activities. Jede Activity lebt zu einem Zeitpunkt auf genau einem Place. Beim Programmstart wird automatisch eine Activity gestartet, die bei der main-Methode beginnt. Mehrere Activities rechnen also potentiell parallel. Tatsächlich werden alle Activities aus einem Threadpool versorgt, der für den Programmierer aber vollkommen transparent ist. Die Laufzeitumgebung von X10 weißt den Threads aus dem Pool nach einer eigenen Policy Activities zu, was vom Programmierer nicht direkt beeinflusst werden kann. Eine neue Activity kann ausschließlich mit dem Keyword \textit{async} gestartet werden. \textit{ async x = calculateX();} führt nebenläufig \textit{calculateX()} aus und weist \textit{x} dann das Ergebnis zu. Um auf die Fertigstellung zu warten, gibt es das Keyword \textit{finish\{...\}}, auf das ein Codeblock folgt. Bevor eine Activity einen finish-Block verlässt, wartet sie, bis alle (auch transitiv) von dieser Activity durch \textit{async}s in diesem Block gestarteten Activities beendet wurden.\cite{x10Spec:2012:Online}
% subsection das_keyword_textit_async (end)

\subsection{Places und das Keyword \textit{at}} % (fold)
\label{sub:places_und_das_keyword_at}
Ein Place in X10 ist die Abstraktion eines Prozessors oder eines Prozessorkerns, auf dem gerechnet werden kann. Zwei unterschiedliche Places haben keinen gemeinsamen Speicher. Um zwischen Places zu wechseln und zu kommunizieren erfolgt kein explizites Message Passing. Stattdessen gibt es das Keyword \textit{at(place) \{ /* code */ \}}. Mit \textit{at} wechselt die aktuelle Activity den Place. Der Code innerhalb des \textit{at}-Blockes wird auf dem entfernten Place ausgeführt. Dazu werden bei jedem \textit{at} alle Objekte, die innerhalb des Blockes verwendet werden, auf den Ziel-Place kopiert. Der Kontrollfluss kehrt erst nach vollständiger Ausführung des Blockes wieder zu dem initialen Place zurück. Die Activity, die den Place-Wechsel veranlasst hat, blockiert, bis das Ergebnis des \textit{at}-Blockes zurück kommt. Ein \textit{at} ist aus Programmierersicht also ein synchrones Konstrukt. Änderungen an Daten innerhalb eines \textit{at}-Blockes werden nicht auf den initialen Place übernommen. Bei jedem \textit{at}, das von Place p nach k wechselt, werden alle benötigten Daten erneut von p nach k kopiert. Benötigte Daten sind dabei definiert, als alle Objekte und Werte, die von allen Zeigern, die innerhalb des \textit{at}-Blockes verwendet werden, (transitiv) erreicht werden können. Oft wird ein \textit{at} mit eine \textit{async} verbunden. \textit{async at(place) { code }} startet quasi eine neue Activity auf dem Place place, die initialisierende Activity wird aber nicht blockiert. \textit{async at} und \textit{finish} funktionieren ganz intuitiv miteinander. \cite{x10Spec:2012:Online}
% subsection das_keyword_at (end)

\subsection{Distributions und distributed Arrays} % (fold)
\label{sub:distributions_und_distributed_arrays}
Distributions und DistArrays sind ein Konzept von X10, um Daten auf Places aufzuteilen. Im X10 Jargon nennt man den Index eines Arrays \textit{Point}. Eine Distribution ist ein Objekt, das zu jedem Point eines Arrays einen Place ausrechnen kann. Ein DistArray (DistributedArray) ist nun ein Array, dessen Werte verteilt auf verschiedenen Places liegen und nur von dem jeweiligen Place aus erreichbar sind. Wo ein Wert liegt, definiert die Wahl der Distribution, die schon bei Arrayerstellung bekannt sein muss. Es kann beispielsweise auf jedem Place ein möglichst gleichgroßer, zusammenhängender Block liegen (Block Distribution) oder jeweils eine Sequenz von k Werten auf einem Place, die nächsten k auf dem nächsten Place liegen, usw., wobei nach dem letzten wieder der erste Place kommt (Cyclic Distribution). Auf die Werte, die auf einem Place liegen darf, ausschließlich von diesem Place aus zugegriffen werden. \cite{x10Spec:2012:Online}
% subsection distributions_und_distributed_arrays (end)

% section die_programmiersprache_x10 (end)

\section{Breitensuche} % (fold)
\label{sec:breitensuche}

Breitensuche (oft BFS vom englischen Breadth-First-Search) ist einer der fundamentalen Graphtraversierungsalgorithmen der Informatik. Die Breitensuche startet bei einem Knoten, dem Wurzelknoten. Die Ausgabe der Breitensuche ist zu jedem Knoten eine Zahl, die BFS Distanz. Die BFS Distanz des Knoten i ist die Länge eines kürzesten Pfades von der Wurzel zu i, gemessen in Anzahl der traversierten Kanten. Ist der Knoten nicht erreichbar, ist die BFS-Distanz $\infty$. Außerdem gibt die Breitensuche zu jedem Knoten i den Vorgängerknoten j aus, sodass j der vorletzte Knoten auf einem kürzesten Pfad von der Wurzel zu i ist. Damit gibt die Breitensuche also für einen gegebenen Startknoten den kürzesten Weg zu jedem erreichbaren Knoten sowie dessen Länge aus.

\subsection{Funktionsweise} % (fold)
\label{sub:funktionsweise}
Es wird jedem Knoten vor Beginn die BFS Distanz $ \infty $ zugewiesen, einzig der Startknoten bekommt die Distanz 0, außerdem wird er einer Liste von aktiven Knoten hinzugefügt. In einer Breitensuchiteration wird nun jeder Knoten, der von einem der aktiven Knoten aus erreichbar ist, angeschaut. Ist seine BFS Distanz $ \infty $, so wird die Distanz auf die um eins erhöhte Distanz des Vorgängerknotens gesetzt. Ist die Distanz kleiner als unendlich, wird der Knoten ignoriert, da der kürzeste Weg bereits gefunden wurde. Die Vereinigung aller Knoten, deren BFS Distanz während einer Iteration reduziert wird, ist die Menge der aktiven Knoten für die nächste Iteration. Sobald am Ende einer Iteration kein Knoten für die nächste Iteration als aktiv markiert ist, ist die Berechnung abgeschlossen. 

Der Algorithmus berechnet für jeden Knoten k also folgendes Minimum\cite{Hassaan:2010:OUA:1854273.1854341}:
$$
bfsDistanz(k) =  \min_{v \in Vorg\ddot{a}nger \; von \; k} (level(v))+1
$$

% subsection funktionsweise (end)

\subsection{Sequentieller BFS Pseudocode} % (fold)
\label{sub:sequentieller_bfs_pseudocode}
Der Pseudocode für eine sequentielle Breitensuche kann wie in Algorithmus \ref{alg:sequential_bfs} aussehen. Statt den zwei Listen \textit{current} und \textit{nexts} wird oft eine einzelne Queue verwendet. Dadurch spart man sich die äußere Schleife und iteriert stattdessen solange über die Elemente der einzelnen Queue, sie leer ist. Hier wird eine Variante mit zwei Listen, eine für die aktuelle und eine für die nächste Iteration, bevorzugt, weil die Laufzeit darunter nicht leidet, sie den Vorteil hat, dass sie der parallelen Version im nächsten Kapitel aber ähnlicher ist.

\begin{algorithm}
	\caption{Sequentielle Breitensuche}
	\label{alg:sequential_bfs}
	\begin{algorithmic}[1]
		\State current : List<Node>()
		\State nexts : List<Node>()
		\State s : Node
		\State  $\forall i: \; bfsDistance(i) \gets \infty$
		\State $bfsDistance(s) \gets 0$
		\State $current.add(s)$
		\While{$current.size() > 0$}
			\For{all nodes i in current}
				\For{all successors j of i}
					\If{$bfsDistance(j) = \infty $}
						\State $bfsDistance(j) \gets bfsDistance(i) + 1$
						\State $nexts.add(j)$
					\EndIf
				\EndFor
			\EndFor
			\State $current \gets nexts$
			\State $nexts.clear()$
		\EndWhile
	\end{algorithmic}
\end{algorithm}

% subsection sequentieller_bfs_pseudocode (end)

\subsection{Analyse} % (fold)
\label{sub:analyse}
Eine Breitensuche hat die asymptotische Laufzeit von $O(n + m)$, wenn n die Anzahl der Knoten und m die Anzahl der Kanten ist. Informell ist das dadurch begründbar, dass die innerste Schleife (Zeile 9-13) höchstens m mal durchlaufen wird (insgesamt, nicht pro Schleifendurchlauf der äußeren Schleife). Da jeder Knoten höchstens einmal zu \textit{current} hinzugefügt wird und in jeder Iteration \textit{current} geleert wird, kann die Bedingung in Zeile 7 höchstens n mal erfüllt sein. Ebenso kann jeder Knoten höchstens einmal in Zeile 8 aus current genommen werden. Damit wird Zeile 9 $O(n)$ mal erreicht. Zeile 9 wird also sowohl höchstens n mal, als auch höchstens m mal erreicht. Eine obere Schranke im O-Kalkül ist damit $O(max(n,m))$, was gerade $O(n + m)$ entspricht.
% subsection analyse (end)
\subsection{Breitensuche in der Wikipedia} % (fold)
\label{sub:wikipedia_und_die_philosophie}
Ein Anwendungsbeispiel für die Breitensuche liefert der bekannte Webcomic xkcd. Es wird folgende Behauptung aufgestellt: Wenn man in der Wikipedia wiederholt auf den ersten Link klickt (der nicht in Klammern steht), gelangt man irgendwann zu dem Arikel über Philosphie \cite{xkcd:Online}. Im Rahmen dieser Arbeit wurde die deutsche Wikipedia heruntergeladen, zu einem Graph verarbeitet und mittels Breitensuche herausgefunden,
\begin{enumerate}
	\item dass diese Behauptung für ca. 42\% der Artikel wahr ist,
	\item dass man durchschnittlich 5,52 mal klicken muss, um zum Artikel \enquote{Philosphie} zu gelangen, falls das denn möglich ist,
	\item dass es einen Zykel gibt: Philosphie $\rightarrow$ Wissenschaft $\rightarrow$ Wissen $\rightarrow$ Erkenntnistheorie $\rightarrow$ Philosphie. Punkt 1 gilt also für alle vier Wikipediaartikel
	\item und dass die Wissenschaft noch \enquote{zentraler} in der Wikipedia ist. Die durchschnittliche Klickanzahl ist hier bei nur 4,49.
\end{enumerate}
Den eigentlichen Zweck des Graphs, nämlich als Testdatum zu fungieren, konnte er leider nicht erfüllen, da er einfach zu klein ist, um sich für die Parallelisierung zu eignen.
% section breitensuche (end)

\section{Invasives Rechnen} % (fold)
\label{sec:invasives_rechnen}
Im Rahmen dieser Arbeit wurde die Breitensuche für das invadeX10 Framework \cite{SWB-367212986} portiert, das im InvasIC Projekt entwickelt wird. Dieses Framework realisiert das Programmierparadigma des invasiven Rechnens. Das invasive Rechnen ist ein Ansatz, der dem Programmierer die Entwicklung von ressourcengewahrem Programmcode ermöglichen soll. Das Ziel dabei ist, die Effizienz eines gesamten Systems zu steigern, das heißt mehr Rechenjobs pro Zeit zu verrichten, als es mit herkömmlichen Scheduling möglich ist. Das kann nur dadurch geschehen, dass die Verwaltungsstelle für Rechenressourcen mehr über ein Programm weiß, als ob es rechnen will oder nicht. Der Vergleich eines einzelnen Programms, das nicht ressourcengewahr die gesamte Rechenleistung benutzt mit einem einzelnen Programm, dass ressourcengewahr arbeitet, geht im besten Fall unentschieden aus. Das ressourcengewahre Programm muss ebenso alle Berechnungen durchführen, die das herkömmliche Programm ausführt, es muss aber zusätzlich noch auf Ressourcennutzung und -verwaltung achten. Deswegen ist und soll ein invasives Programm nicht schneller, als sein herkömmlich parallelisiertes Gegenstück sein.

Im invadeX10 Framework hat jedes Programm, das zu einem Zeitpunkt läuft, einen Agent, der die Schnittstelle zum System darstellt. Über den Agent regelt das Programm Ressourcenanfragen und -abgaben. Gibt es konkurrierende Ressourcenanfragen verschiedener Programme, handeln die betroffenen Agenten unter sich eine Lösung aus.
\subsection{Grundoperationen} % (fold)
\label{sub:grundoperationen}

Im invadeX10 Framework gibt es drei grundlegende Operationen, um mit dem Betriebssystem zu kommunizieren.
\begin{description}
	\item[Invade] Das Programm baut sich zunächst einen sogenannten Constraint zusammen. Ein Constaint ist ein Objekt, dass die Ressourcenforderung eines Programms enthält, etwa die Anzahl an Processing Elements, die eine abstrakte Repräsentation von CPU-Cores sind. Dieser Constraint wird bei dem \textit{invade} Aufruf an den Agenten übergeben. Der Agent versucht nun, die Forderungen möglichst gut mit freien Ressourcen zu erfüllen, wenn nötig auch in Absprache mit den anderen Agenten und dem globalen System. Das Ergebnis der Anforderung wird in ein Claimobjekt verpackt an das Programm zurückgegeben. Die durch den Claim abstrahierten Ressourcen sind nun für dieses Programm reserviert. Da ein Programm bei der Operation ehemals freie Ressourcen quasi besetzt, wird sie \textit{invade} genannt.
	\item[Infect] Die \textit{infect} Operation \enquote{infiziert} die Ressourcen mit Programmcode und Daten. Das Programm übergibt dazu dem Claim eine Funktion, meist \textit{ilet} genannt. Die referenzierte Funktion wird dann auf jeder Ressource dieses Claims nebenläufig ausgeführt. Zur Kommunikation stehen herkömmliche X10 Primitive und APIs zur Verfügung. Auf einen und denselben Claim kann mehrmals infect aufgerufen werden, die zugewiesenen Ressourcen \enquote{verbrauchen} sich also nicht bei einer Berechnung.
	\item[Retreat] Mit der \textit{retreat} Operation teilt das Programm dem Agenten mit, dass bestimme Ressourcen, die dem Programm zugewiesen wurden, nicht mehr benötigt werden und damit wieder für alle anderen zur Verfügung stehen. Ein Retreat ist unwiderruflich. Das bedeutet, dass erneut ein invade aufgerufen werden muss, falls später wieder mehr Rechenleistung benötigt wird. Ein temporäres Abgeben mit späterem zurückholen von Ressourcen ist vorgesehen aber noch nicht umgesetzt.
\end{description}

Ein sehr einfaches Programm könnte beispielsweise folgende Struktur aufweisen:

$$\mathit{invade}\rightarrow\mathit{infect}\rightarrow\mathit{retreat}$$
Ein komplexeres, iterierenderes Programm könnte aber auch diese Struktur bei jeder Iteration wiederholen. Der Vorteil davon ist nicht, dass das Programm schneller ausgeführt wird, sondern die Möglichkeit, brachliegende Ressourcen abzugeben oder mehr Rechenleistung zu beantragen. Ein Programm kann jederzeit weitere Ressourcen anfordern, Ressourcen infizieren oder die eigenen Ressourcen zum Teil oder vollständig abgeben. 
% subsection grundoperationen (end)
% section invasives_rechnen (end)
% chapter grundlagen (end)