%!TEX root = thesis.tex

\chapter{Breitensuche im invasiven Kontext} % (fold)
\label{cha:breitensuche_im_invasiven_kontext}
In diesem Kapitel wird beschrieben, wie die Breitensuche unter Verwendung des Frameworks invadeX10 implementiert wurde. Aus Zeitgründen konnte in dieser Arbeit nur ein Ansatz herausgearbeitet werden, der noch nicht alle Möglichkeiten des invasiven Rechnens nutzt. Deswegen ist womöglich an einigen Stellen im Algorithmus nicht sofort ersichtlich, weswegen bestimmte Lösungsansätze gewählt wurden. Das liegt daran, dass die Struktur der Implementierungen so gewählt wurde, dass zukünftige Ideen leicht umsetzbar sind.

\section{Der Algorithmus} % (fold)
\label{sec:der_algorithmus}

\subsection{Unterschiede zum nicht invasiven Fall} % (fold)
\label{sub:unterschiede_zum_nicht_invasiven_fall}
Zunächst seien in diesem Kapitel einige Unterschiede in den Anforderungen und der Problemstellung erläutert. Die Beschreibung der jeweiligen Lösungen finden sich in dann in Kapitel \ref{sub:ablauf_des_algorithmus}.

\subsubsection{Asymmetrie der Rechenleistung} % (fold)
\label{ssub:asymmetrie_der_rechenleistung}
Im invasiven Rechnen gibt es das Konzept des Processing Elements (abgekürzt PE). Ein PE ist die abstrakte Repräsentation eines Rechenkerns, auf dem ein Thread ausgeführt werden kann. Jedes PE repräsentiert genau eine Recheneinheit in der Hardware die in einem bestimmten Bereich mit gemeinsamen Speicher liegt. Dieser Bereich mit gemeinsamen Speicher wird durch X10 mittels Places abstrahiert. Es kann zum Beispiel ein Prozessor mit 8 Cores vorliegen. Im invadeX10-System existieren dann 8 PEs, die alle auf dem selben Place liegen. Synchronisation und Kommunikation zwischen zwei Activities auf dem selben Place geht wesentlich schneller, was sowohl Bandbreite als auch einmalige Startzeit der Kommunikation betrifft, als wenn die Activities auf unterschiedlichen Places liegen. 

Die Breitensuche wie in Kapitel \ref{sec:1d_partitionierung} behandelt das Problem, indem er auf jedem Place gleich viele Daten und damit gleichviel Rechenarbeit legt. Es wird auf jedem Place zunächst genau eine Activity gestartet, die dann zum Beispiel auf Schleifenebene Nebenläufigkeit erzeugt. Es gibt quasi zwei klare Hierarchiestufen der Parallelität. Dieser Ansatz geht davon aus, dass alle Places gleich schnell rechnen.

Im invasiven Fall fragt das Programm bei dem Agenten nach Rechenleistung und bekommt daraufhin eine gewisse Menge an PEs als Antwort zurück. Selbst wenn durch Constraints festgelegt würde, dass die PEs gleichmäßig auf Places verteilt sein sollen, kann der Agent das in Abhängigkeit der aktuellen Situation des Gesamtsystems nicht garantieren. Deswegen kann sich das Programm nicht darauf verlassen. Das Programm findet sich also in der Situation, dass es beispielsweise drei PEs, eine auf Place 0 und zwei auf Place 3 hat. Die erste Konsequenz muss sein, dass auf Place 3 doppelt so viele Daten wie auf Place 0 liegen. Im Falle der Breitensuche werden Place 3 also doppelt so viele Knoten gehören wie Place 0. Wird nun ein infect auf die drei PEs aufgerufen, werden korrekterweise drei Activities gestartet, die alle denselben Code ausführen. Allerdings stehen die zwei Activities, die auf dem selben Place laufen, in einem anderen Verhältnis zueinander, als zwei Activities, die auf verschiedenen Places laufen. Die Activities haben für die folgenden Erläuterungen die Nummern 0,1 und 2, wobei Activity 0 auf Place 0 und entsprechen 1 und 2 auf Place 3 liegen.
% TODO: Andreas fragen, ob das wirklich nicht garantiert werden kann (Zeile hier drüber)
\begin{itemize}
	\item Will Activity 0 Daten an 1 und 2 schicken, so ist es effizienter diese in einem Kommunikationsvorgang zusammenzufassen, als das IPC-System zweimal zu starten
	\item Ebenso sollten Activity 1 und 2 gemeinsam ihre Daten an Activity 0 schicken.
\end{itemize}
% subsubsection asymmetrie_der_rechenleistung (end)
Eine Activity muss also den gesamten Kontext kennen und wissen, ob und in welchem Fall sie sich mit anderen Activities auf dem selben Place zusammen tun muss.

\subsubsection{Dynamische Ressourcenverwaltung und Verteilung der Daten} % (fold)
\label{ssub:dynamische_ressourcenverwaltung}
Hier ist prinzipiell ein Designentscheidung zu treffen, da sich zumindest bei der Breitensuche nur schwer folgende Ziele vereinbaren lassen:
\begin{itemize}
	\item Dynamisches invade und retreat je nach benötigter Rechenleistung.
	\item Daten so verteilen, dass die Rechenleistung ideal ausgenutzt wird.
\end{itemize}
\underline{Erklärung:} Die Situation sei wie in \ref{ssub:asymmetrie_der_rechenleistung}, eine PE auf Place 0, zwei PEs auf Place 3. Es sei bereits eine Iteration der Breitensuche abgeschlossen. Nun ist bekannt, wie viele der Knoten, die auf Place 0 liegen, aktiv sind und wieviel Knoten, die auf Place 3 liegen, aktiv sind. Die Situation sei so, dass beide ungefähr gleich viele Knoten in der nächsten Iteration zu bearbeiten haben, obwohl auf Place 3 ja die doppelte Menge an Knoten liegt. Die doppelte Rechenleistung auf Place 3 ist damit in der nächsten Iteration nicht zu gebrauchen, da die beiden Activities auf Place 3 nach der abgeschlossenen Iteration auf Place 0 warten müssten, der für die selbe Iteration ungefähr doppelt so lange benötigen wird. Eine ressourcengewahres System würde also eine der beiden PEs auf Place 3 abgeben. Jetzt steht auf den beiden Places gleichviel Rechenleistung zu Verfügung. Durchschnittlich ist die Liste der aktiven Knoten auf Place 3 aber doppelt so lang wie die Liste auf Place 0. Die Anwendung kann nun in einer späteren Iteration versuchen, wieder eine PE auf Place 3 zu bekommen. Allerdings kann diese bereits von einer anderen Anwendung besetzt sein. Zudem entspricht es nicht exakt dem Paradigma des invasiven Rechnens, dem Agenten mitteilen zu müssen, welche PE genau gewünscht ist.

Die naheliegende Antwort auf dieses Problem ist die Umverteilung der Daten, so dass gleich viele Daten auf Place 0 und 3 liegen, zumindest bis die gewünschte PE wieder verfügbar ist. Dieser Ansatz wurde im Rahmen dieser Arbeit nicht betrachtet, da er zum einen sehr aufwendig zu implementieren ist und zum anderen zu erwarten ist, dass die Performance sehr schlecht ist. Es müssten große Datenmengen (Adjazenzlisten, Distanzarrays) verschickt werden, größere Arrays alloziert werden, usw.

Zusammenfassend kann man sagen, dass ein Algorithmus, der auf partitionierten Daten (ein Graph bei BFS) arbeitet, nur sehr schwierig gleichzeitig temporär ungenutzte Ressourcen abgeben und trotzdem noch maximal effizient arbeiten kann. In dieser Arbeit entspricht zwar jede BFS-Iteration einem \textit{invade}, allerdings werden zwischen den Iterationen keine Ressourcen abgegeben oder angefordert.
% subsubsection dynamische_ressourcenverwaltung (end)

\subsubsection{Nicht fortlaufende Indizes} % (fold)
\label{ssub:nicht_fortlaufende_indizes}
Trotz Verwendung des InvaIC Frameworks, soll die X10 API weiter genutzt werden können. Die X10-Funktionalitäten rund um Distributions, und DistArrays arbeitet auf der Basis von Places und deren Nummerierung. Aus diesem Grund kann man im invasiven Fall nicht komplett von der Vorstellung von Places weggehen, sondern muss im Auge behalten, auf welchem Place welche Daten liegen. Im reinen X10 sind die Places immer von 0 bis p-1 (bei p Places) durchnummeriert. Das macht die Nummer eines Places zu einem sehr praktischen Ausgangspunkt, um mit Indizes zu rechnen. Es kann zum Beispiel ein DistArray der Größe p erstellt werden, wenn auf jedem Place genau ein Datum liegen soll und jeder Place kann mit seinem eigenen Index auf seine eigenen Daten zugreifen.

Im invasiven Fall werden vom Agent zunächst nur ProcessingElements bereitgestellt. Auf welchem Place diese liegen, ist für den Klienten nur bedingt beeinflussbar, sofern er nicht bereit ist auf Rechenleistung zu verzichten. Dadurch ist keine natürliche Nummerierung der Places mehr vorhanden. Es lässt sich nicht vermeiden, etwas Speicherplatz und Rechenleistung zu benutzen, um dieses Problem zu lösen. Der unten stehende Vergleich des Codes zum Feststellen, welcher der besitzende Place von Knoten k ist, verdeutlicht das Problem. $p$ ist die Anzahl an Places, \textit{placesList} eine Liste aller Places und \textit{mapNodeToPlaceIndex} ein Funktion. Damit diese Funktion funktioniert, muss vorher schon eine Datenstruktur mit dem vollständigen wissen über alle PEs initialisiert worden sein.
\begin{algorithm}
	\caption{Durchnummerierter Fall, wie in Kapitel \ref{sec:1d_partitionierung}}
	\label{alg:owner_consecutive}
	\begin{algorithmic}[1]
		\State \textbf{val} owner = k / p
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Nicht durchnummerierter Fall, wie in diesem Kapitel}
	\label{alg:owner_random}
	\begin{algorithmic}[1]
		\State \textbf{val} ownerId = mapNodeToPlaceIndex(k) // Position des owners in der placesList
		\State \textbf{val} owner   = placesList[ownerId]
	\end{algorithmic}
\end{algorithm}
% subsubsection nicht_fortlaufende_indizes (end)

Das Problem wurde gelöst, indem mit eine Art virtuelle Placesverwaltung eingeführt wurde. Direkt nachdem bekannt ist, welche PEs zur Verfügung stehen, werden alle Places in einer Liste sortiert. Ab diesem Zeitpunkt wird ausschließlich mit dem Rang des Places in der sortierten Liste gerechnet. Die Ränge sind durchnummeriert von 0 bis p-1, womit die gewünscht Situation hergestellt ist. Die einzige Stelle, an der wieder das ursprüngliche Placeobjekt verwendet werden muss, ist beim Argument eines at{}-Blocks. Der Zugriff geht  über den Index in konstanter Zeit.

% subsection unterschiede_zum_nicht_invasiven_fall (end)
\subsection{Ablauf des Algorithmus} % (fold)
\label{sub:ablauf_des_algorithmus}
Aus Zeitmangel wurde im Rahmen dieser Arbeit die Breitensuche im invasiven Fall nur mittels der 1D-Dekomposition implementiert. Grundsätzlich ist der selbe Algorithmus wie in Kapitel \ref{sec:1d_partitionierung} beschrieben implementiert. In diesem Kapitel werden deswegen in erster Linie die gewählten Lösungsansätze zu den Problem aus Kapitel \ref{sec:der_algorithmus} beschrieben.
\begin{figure}[ht]
	\centering
	\label{img:invasive-flow}
	\includegraphics{pics/invasive-flow.pdf}
	\caption{Grundsätzlicher Ablauf der Breitensuche. Zu beachten ist, dass zwischen den einzelnen Iterationen kein \textit{retreat} und kein invade stattfindet.}
\end{figure}

\subsubsection{Dekomposition und Datenhaltung} % (fold)
\label{ssub:dekomposition_und_datenhaltung}

Sobald der Algorithmus nach dem Start den Graph vollständig eingelesen hat und die Antwort des \textit{invade} bekommen hat (eine Liste von PEs), beginnt er damit, sich die benötigten Datenstrukturen aufzubauen.
\begin{itemize}
	\item ProcessingElements nach Placenummer sortieren. Liste alle involvierten Places in eben dieser Reihenfolge aufstellen und zu jedem Place die Anzahl an verfügbaren PEs in ein Array schreiben. An der Stelle 0 in diesem Array steht also, wie viele PEs auf dem Place zur Verfügung stehen, der in der Placeliste an erster Stelle (Index 0) steht.
	\item Die Menge an Knoten wird so unterteilt, dass jede PE ein gleichgroßen Teil bekommt. Wichtig ist, dass alle PEs, die auf dem selben Place liegen, benachbarte Intervalle der Knotenliste bekommen. Es wird entsprechend Platz für die Adjazenzlisten auf den Places reserviert. Alle Knoten, die zu einem Place gehören, gehören allen dortigen PEs gemeinsam. Um aufzulösen, welchem Place ein Knoten gehört, wird ein Array berechnet, dass für jede PE (in der Reihenfolge der Liste aus dem ersten Punkt) enthält auf welchem Place sie liegt. Um den Besitzer von Knoten k zu finden, muss so zur Laufzeit nur noch k durch die Anzahl an PEs geteilt werden. Das Ergebnis ist die Stelle der Placeliste, an der der besitzende Place steht.
	\item Das Selbe muss für das DistArray passieren, dass die BFS-Distanzen halten soll.
	\item Es wird pro Place für jeden anderen Place ein Empfangspuffer erstellt. Diese Empfangspuffer befinden sich in einem DistArray mit einer UniqueDist, das bedeutet, dass auf jedem Place genau ein Datum(=Array aus Puffern) liegt.
	\item Es werden pro Place genau soviele Listen für aktive Knoten erstellt, wie es aktive PEs auf diesem Place gibt.
\end{itemize}


% subsubsection dekomposition_und_datenhaltung (end)
\subsubsection{Zweistufiges Infect und Indizierung} % (fold)
\label{ssub:zweistufiges_infect}
Der Algorithmus verwendet die \textit{Clock}-Funktionalität von X10. Eine Clock entspricht einer Barriere, die alle Aktivitäten bei Erreichen so lange blockiert, bis alle registrierten Aktivitäten die Barriere erreicht haben. Es wird sowohl für alle Aktivitäten (es gibt eine Aktivität pro PE) global eine Clock benötigt, als auch lokal zwischen je allen Aktivitäten, die auf dem selben Place liegen. Um diese Clocks zu erstellen, ist es nötig den Infect-Aufruf manuell zweistufig zu implementieren. Zunächst wird die globale Clock erstellt, dann wird eine Aktivität pro involviertem Place gestartet, die sich aber nicht in der Clock registrieren. Anschließend wird von der einen Aktivität auf jedem Place eine weitere Clock erstellt und pro PE, die auf diesem Place zur Verfügung steht eine Aktivität gestartet. Diese Aktivität registriert sich jetzt in beiden oben erstellten Clocks und beginnt mit der BFS.

Ein weiterer Vorteil des zweistufigen Infects ist es, dass sehr einfach jeder Aktivität ein globaler Index und ein lokaler Index gegeben werden kann. Der lokale Index ist die Nummer einer Aktivität auf einem Place. Vor allem der lokale Index wird im Weiteren sehr nützlich sein.
% subsubsection zweistufiges_infect (end)

\subsubsection{Lokale Parallelität} % (fold)
\label{ssub:lokale_parallelit_t}
Wie die Kollaboration zwischen den einzelnen Places aussieht wurde bereits in Kapitel \ref{sec:1d_partitionierung} beschrieben. Ein Place als ganzes Verhält sich im invasiven Fall exakt gleich. Allerdings gibt es keine \enquote{Masteraktivity} pro Place, die Jobs verteilen kann und für die Synchronisation sorgt. Stattdessen werden mehrere gleichberechtigte Activities gestartet, die trotzdem auf den selben Daten arbeiten sollen. In diesem Abschnitt wird beschrieben, wie diese Zusammenarbeit gelöst wurde. Dazu werden die Phasen aus Kapitel \ref{sec:1d_partitionierung} aufgegriffen. Eine genaue Beschreibung der einzelnen Phasen findet sich auch dort und wird hier nicht wiederholt. Wichtig ist, dass jede Activity die Information hat, die wievielte von wie vielen sie auf diesem Place ist.

\subsection{Phase 1: Adjazente Knoten sortieren} % (fold)
\label{sub:phase_1_invasive}
Die Liste der aktiven Knoten für jede PE einmal vorhanden. Es handelt sich dabei um ein Array von Arraylisten, so dass der Zugriff auf ein beliebiges Element einer beliebigen Liste sehr schnell in konstanter Zeit geschehen kann. Zunächst zählt jedes PE zusammen, viewiele Elemente insgesamt in allen Listen liegen, also wieviele aktive Knoten es auf diesem Place gibt. Jedes PE rechnet sich nun aus, welcher Teil der aktiven Knoten, ihr zustehen. Zum Beispiel berechnet PE 0: 5 Elemente ab Index 0 und PE1 3 Elemente ab Index 5. Aus welchen Listen diese Elemente stammen ist zu diesem Zeitpunkt nicht bekannt. Es könnten zum Beispiel alle Elemente in der zweiten Liste liegen. Der Algorithmus, um über alle Elemente zu iterieren, ist in \ref{alg:iterate_active_nodes} beschrieben.

\begin{algorithm}
	\caption{Über mehrere Listen iterieren}
	\label{alg:iterate_active_nodes}
	\begin{algorithmic}[1]
		\State var min : Int // Start Index of Region
		\State var listIndex : Int = 0
		\For{counter $\in$ length-1..0}

			// Skip to the list containing the first element
			\While{min $\le$ activeNodes(listIndex).size}
				\State min -= activeNodes(listIndex).size
				\State listIndex++;
			\EndWhile

			// calculate how many elements to take from current list
			\State val upperBoundForThisList = min(current(listIndex).size(), min + counter);
            \State val elementsTakenFromThisList = upperBoundForThisList - min;
            \State counter -= elementsTakenFromThisList; // if counter < 0, the outer loop ends

            \For{idx=min; idx < upperBoundForThisList; idx++}
            	\State element = activeNodes(listIndex)(idx)
            	\State // Do Stuff
            \EndFor
            \State min = activeNodes(listIndex).size() // The next element is from the next list

		\EndFor
	\end{algorithmic}
\end{algorithm}
Es wird zu jeder Zeit durch den \textit{listIndex} die aktuell akive Liste gespeichert. Die erste while-Schleife springt solange zur nächsten Liste, bis der Index innerhalb der aktuellen Liste ist. Dazu wird in jeder Iteration die Größe der aktuellen Liste von Startindex abgezogen. Wenn der Startindex innerhalb der aktuellen Liste ist, wird while-Schleife verlassen. Danach wird ausgerechnet, wie lange Elemente aus der aktuellen Liste genommen werden. Wenn noch mehr Elemente gebraucht werden, als die Liste lang ist, dann ist die Obergrenze die Listengröße, ansonsten der Startindex + Anzahl an Elementen.

Es steht pro Zielplace aber nur ein Sendpuffer zur Verfügung, in welchen alle Activities konkurrierend schreiben. Deswegen muss sichergestellt werden, dass der Zugriff auf jeden Buffer atomar passiert. Nach dieser Phase ist lediglich eine lokale Barriere nötig um sicherzustellen, dass alle Sendepuffer korrekt und vollständig geschrieben wurden. 
% subsection phase_1 (end)

\subsection{Phase 2: Kommunikation} % (fold)
\label{sub:parallel_phase_2_invasive}
In Phase 2 werden die Sendepuffer gesendet. Eine Aktivität ist für einen Sendepuffer genau dann zuständig, wenn die ID des Ziels modulo der Anzahl an Activities auf diesem Place der lokalen ID dieser Aktivität entspricht. Ansonsten ist hier nichts anzupassen. Nach dem Senden wird eine globale Barriere benötigt, damit alle Empfangspuffer korrekt geschrieben wurden, bevor diese ausgewertet werden.
% subsection phase_2 (end)

\subsection{Phase 3: BFS-Distanz aktualisieren} % (fold)
\label{sub:phase_3_invasive}
Wie in Phase 2 liest eine Activity genau dann einen Empfangspuffer, wenn die ID des Senders modulo Anzahl an Activities auf diesem Place die lokale ID der Activity ergibt. Diese Aufteilung der Arbeit entspricht nicht unbedingt einer gleichmäßigen Aufteilung der Arbeit, geht aber fast ohne Synchronisation. Einzig die Liste der aktiven Knoten für die nächste Iteration muss atomar geschrieben werden.
% subsection phase_3 (end)

% subsubsection lokale_parallelit_t (end)
\subsubsection{Allreduce} % (fold)
\label{ssub:allreduce_invasive}
Das Allreduce ist im invasiven Fall insofern nicht mehr nötig, als dass es keine All-to-All Operation mehr ist. Es wird ohnehin nach jeder BFS-Iteration zunächst die Berechnung gestoppt und nur falls eine weitere Iteration nötig ist erneut ein \textit{infect} aufgerufen. Das Ergebnis der aktuellen Iteration schreiben alle Activities in ein Array, das Anfangs erstellt wird und dass eine Zelle für jede Activity bereithält. Um das Array zu adressieren, wird jeder Activity eine GlobalRef übergeben. Die Master-Activity reduziert dieses Array dann lokal um festzustellen, ob der Algorithmus fertig ist. Falls nicht, wird eine weitere Iteration gestartet.
% subsubsection allreduce (end)
% subsection ablauf_des_algorithmus (end)
% section der_algorithmus (end)	


% chapter breitensuche_im_invasiven_kontext (end)