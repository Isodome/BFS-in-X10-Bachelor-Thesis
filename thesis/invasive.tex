%!TEX root = thesis.tex

\chapter{Breitensuche im invasiven Kontext} % (fold)
\label{cha:breitensuche_im_invasiven_kontext}
In diesem Kapitel wird beschrieben, wie die Breitensuche unter Verwendung des Frameworks InvasIC implementiert wurde. Aus Zeitgründen konnte in dieser Arbeit nur der Ansatz herausgearbeitet werden, der noch nicht alle Möglichkeiten des invasiven Rechnens nutzt. Deswegen ist womöglich an einigen Stellen im Algorithmus nicht sofort ersichtlich, weswegen bestimmte Lösungsansätze gewählt wurden. Das liegt daran, dass die Struktur

\section{Der Algorithmus} % (fold)
\label{sec:der_algorithmus}

\subsection{Unterschiede zum nicht invasiven Fall} % (fold)
\label{sub:unterschiede_zum_nicht_invasiven_fall}
Zunächst seien in diesem Kapitel einige Unterschiede in den Anforderungen und der Problemstellung erläutert. Die Beschreibung der jeweiligen Lösungen finden sich in dann in Kapitel %TODO: Kapitel einfügen

\subsubsection{Asymmetrie der Rechenleistung} % (fold)
\label{ssub:asymmetrie_der_rechenleistung}
Im invasiven Rechnen gibt es das Konzept des Processing Elements(PE). Ein PE ist die abstrakte Darstellung eines Rechenkernes, auf dem ein Thread ausgeführt werden kann. Jedes PE repräsentiert genau eine Recheneinheit in der Hardware die in einem bestimmten Bereich mit gemeinsamen Speicher liegt. Dieser Bereich mit gemeinsamen Speicher wird durch X10 mittels Places abstrahiert. Es kann zum Beispiel ein Prozessor mit 8 Cores vorliegen. Im InvasIC-System existieren dann 8 PEs, die alle auf dem selben Place liegen. Synchronisation und Kommunikation zwischen zwei Activities auf dem selben Place geht wesentlich schneller was sowohl Bandbreite als auch einmalige Startzeit der Kommunikation betrifft als wenn die Activities auf unterschiedlichen Places liegen. Algorithmen wie in Kapitel \ref{sec:1d_partitionierung} behandeln das Problem, indem sie auf jedem Place gleichviele Daten und damit gleichviel Rechenarbeit legen. Es wird auf jedem Place zunächst genau eine Activity gestartet, die dann zum Beispiel auf Schleifenebene Nebenläufigkeit erzeugt. Es gibt quasi zwei klare Hierarchiestufen der Parallelität. Dieser Ansatz geht davon aus, dass alle Places gleichschnell rechnen.

Im invasiven Fall fragt das Programm bei dem Agenten nach Rechenleistung und bekommt daraufhin eine Menge an PEs als Antwort zurück. Selbst wenn durch Constraints festgelegt würde, dass die PEs gleichmäßig auf Places verteilt sein sollen, kann der Agent das in Abhängigkeit der aktuellen Situation des Gesamtsystems nicht garantieren und somit sich das Programm nicht darauf verlassen. Das Programm findet sich also in der Situation, dass es etwa 3 PEs, eine auf Place 0 und zwei auf Place 3 hat. Die erste Konsequenz muss sein, dass auf Place 3 doppelt so viele Daten wie auf Place 0 liegen. Im Falle der Breitensuche werden Place 3 also doppelt so viele Knoten gehören wie Place 0. Wird nun ein infect auf die drei PEs aufgerufen, werden korrekterweise drei Activities gestartet, die alle denselben Code ausführen. Allerdings haben die zwei Activities auf dem selben Place ein anderes Verhältnis zueinander. Die Activities haben die Nummern 0,1 und 2, wobei Activity 0 auf Place 0 und entsprechen 1 und 2 auf Place 3 liegen.
% TODO: Andreas fragen, ob das wirklich nicht garantier werden kann (zeite hier drüber)
\begin{itemize}
	\item Will Activity 0 Daten an 1 und 2 schicken, so ist es effizienter diese in einem Kommunikationsvorgang zusammenzufassen, als das IPC-System zweimal zu starten
	\item Ebenso sollten Activity 1 und 2 gemeinsam ihre Daten an Activity 0 schicken.
\end{itemize}
% subsubsection asymmetrie_der_rechenleistung (end)

\subsubsection{Dynamische Ressourcenverwaltung und Verteilung der Daten} % (fold)
\label{ssub:dynamische_ressourcenverwaltung}
Hier ist prinzipiell ein Designentscheidung zu treffen, da sich zumindest bei der Breitensuche nur schwer folgende Ziele vereinbaren lassen:
\begin{itemize}
	\item Dynamischs invade und retreat je nach benötigter Rechenleistung.
	\item Daten so verteilen, dass die Rechenleistung ideal ausgenutzt wird.
\end{itemize}
\underline{Erklärung:} Die Situation sei wie in \ref{ssub:asymmetrie_der_rechenleistung}, eine PE auf Place 0, zwei PEs auf Place 3. Es sei bereits eine Iteration der Breitensuche abgschlossen. Nun ist bekannt, wieviele der Knoten, die auf Place 0 liegen, aktiv sind und wieviel Knoten, die auf Place 3 liegen, aktiv sind. Die Situation sei so, dass beide ungefähr gleichviele Knoten in der nächsten Iteration zu bearbeiten haben. Die doppelte Rechenleistung auf Place 3 ist damit in der nächsten Iteration nicht zu gebrauchen, da die beiden Activities auf Place 3 nach der Iteration auf Place 0 warten müssten, der für die selbe Iteration ungefähr doppelt so lange benötigen wird. Eine ressourcengewahres System würde also eine der beiden PEs auf Place 3 abgeben. Jetzt steht auf den beiden Places gleichviel Rechenleistung zu Verfügung. Durchschnittlich ist die Liste der aktiven Knoten auf Place 3 aber doppelt so lang wie die Liste auf Place 0. Die Anwendung kann nun versuchen, wieder eine PE auf Place 3 zu bekommen. Allerdings kann diese bereits von einer anderen Anwendung besetzt sein. Zudem entspricht es nicht exakt dem Paradigme des invasiven Rechnens, dem Agenten mitteilen zu müssen, welche PE genau gewünscht ist.

Die naheliegende Antwort auf dieses Problem ist die Umverteilung der Daten, so dass gleichviele Daten auf Place 0 und 3 liegen, zumindest bis die gewünschte PE wieder verfügbar ist. Dieser Ansatz wurde im Rahmen dieser Arbeit nicht betrachtet, da er zum einen sehr aufwendig zu implementieren ist und zum anderen zu erwarten ist, dass die Performance sehr schlecht sein wird. Es müssten große Datenmengen (Adjazenzlisten, Distanzarrays) verschickt werden, größere Arrays allokiert werden, usw.

Zusammenfassend kann man sagen, dass ein Algorithmus, der auf partitionierten Daten (ein Graph bei BFS) arbeitet, nur sehr schwierig gleichzeitig temporär ungenutzte Ressourcen abgeben und trotzdem noch maximal effizient arbeiten kann. In dieser Arbeit entspricht zwar zum weiteren Testen jede BFS-Iteration einem \textit{invade}, allerdings werden zwischen den Iterationen keine Ressourcen abgegeben oder angefordert.
% subsubsection dynamische_ressourcenverwaltung (end)
\subsubsection{Nicht fortlaufende Indizes} % (fold)
\label{ssub:nicht_fortlaufende_indizes}
Trotz Verwendung des InvaIC Frameworks, soll die X10 API weiter genutzt werden können. Die X10-Funktionalitäten rund um Distributions, und DistArrays arbeitet auf der Basis von Places und deren Nummern. Aus diesem Grund kann man im invasiven Fall nicht komplett von der Vorstellung von Places weggehen, sondern muss im Auge behalten, auf welchem Place was liegt. Im reinen X10 sind die Places immer von 0 bis p-1 (bei p Places) durchnummeriert. Das macht die Nummer eines Places zu einem sehr praktischen Ausgangpunkt, um mit Indizes zu rechnen. Es kann zum Beispiel ein DistArray der Größe p erstellt werden, wenn auf jedem Place genau ein Datum liegen soll und jeder Place kann mit seinem eigenen Index darauf zugreifen.

Im invasiven Fall werden vom Agent zunächst nur ProcessingElements bereitgestellt. Auf welchem Place diese liegen, ist für den Clienten völlig unvorhersehbar und unbeeinflussbar. Dadurch ist keine natürliche Durchnummerierung der Places vorhanden. Der Vergleich des Codes zum Feststellen, wer der Besitzer von Knoten k ist, verdeutlicht das Problem. $p$ ist die Anzahl an Places, \textit{placesList} eine Liste aller Places und \textit{mapNodeToPlaceIndex} ein vorberechnetes Funktion, die vorher wissen muss, wieviele PEs auf welchem Place zur Verfügung stehen.
\begin{algorithm}
	\caption{Durchnummerierter Fall, wie in Kapitel \ref{sec:1d_partitionierung}}
	\label{alg:owner_consecutive}
	\begin{algorithmic}[1]
		\State \textbf{val} owner = k / p
	\end{algorithmic}
\end{algorithm}

\begin{algorithm}
	\caption{Nicht durchnummerierter Fall, wie in diesem Kapitel}
	\label{alg:owner_random}
	\begin{algorithmic}[1]
		\State \textbf{val} ownerId = mapNodeToPlaceIndex(k)
		\State \textbf{val} owner   = placesList[ownerId]
	\end{algorithmic}
\end{algorithm}
% subsubsection nicht_fortlaufende_indizes (end)

% subsection unterschiede_zum_nicht_invasiven_fall (end)
\subsection{Ablauf des Algorithmus} % (fold)
\label{sub:ablauf_des_algorithmus}
Aus Zeitmangel wurde im Rahmen dieser Arbeit die Breitensuche nur mittels der 1D-Dekomposition implementiert. Grundsätzlich ist der selbe Algorithmus wie in Kapitel \ref{sec:1d_partitionierung} beschrieben implementiert. In diesem Kapitel werden vorallem die gewählten Lösungsansätze zu den Problem aus Kapitel \ref{sec:der_algorithmus} beschrieben.
\begin{figure}[ht]
	\centering
	\label{img:invasive-flow}
	\includegraphics{pics/invasive-flow.pdf}
	\caption{Grundsätzlicher Ablauf der Breitensuche. Zu beachten ist, dass zwischen den einzelnen Iterationen kein retreat und kein invade stattfindet.}
\end{figure}

\subsubsection{Dekomposition und Datenhaltung} % (fold)
\label{ssub:dekomposition_und_datenhaltung}

Sobald der Algorithmus nach dem Start den Graph vollständig eingelesen hat und die Antwort des \textit{invade} bekommen hat (eine Liste von PEs), beginnt er damit sich die benötigten Datentrukturen aufzubauen.
\begin{itemize}
	\item ProcessingElements nach Placenummer sortieren. Liste alle involvierten Places in eben dieser Reihenfolge aufstellen und zu jedem Place die Anzahl an verfügbaren PEs in ein Array schreiben. An der Stelle 0 in diesem Array steht also, wieviele PEs auf dem Place zur Verfügung stehen, der in der Placeliste an erster Stelle (Index 0) steht.
	\item Die Menge an Knoten wird so unterteilt, dass jede PE ein gleichgroßen Teil bekommt. Wichtig ist, dass alle Teile, die auf dem selben Place liegen, benachbarte Intervalle der Knotenliste bekommen. Es wird entsprechend Platz für die Adjazenzlisten auf den Places reserviert. Alle Knoten, die zu einem Place gehören, gehören allen dortigen PEs gemeinsam. Um Aufzulösen, welchem Place ein Knoten gehört, wird ein Array berechnet, dass für jede PE (in der Reihenfolge der Liste aus dem ersten Punkt) enthält auf welchem Place sie liegt. Um den Besitzer von Knoten k zu finden, muss so zur Laufzeit nurnoch k durch die Anzahl an PEs geteilt werden. Das Ergebnis ist die Stelle der Placesliste, an der der besitzende Place steht.
	\item Das Selbe muss für das DistArray passieren, dass die BFS-Distanzen halten soll.
	\item Es wird pro Place für jeden anderen Place ein Receivebuffer erstellt. Diese Receivebuffer befinden sich in einem DistArray mit einer UniqueDist, das bedeutet, dass auf jedem Place genau ein Datum(=Array aus Buffern) liegt.
	\item Es wird pro Place eine Liste für aktive Knoten erstellt.
\end{itemize}

% subsubsection dekomposition_und_datenhaltung (end)
\subsubsection{Zweistufiges Infect und Indizierung} % (fold)
\label{ssub:zweistufiges_infect}
Der Algorithmus verwendet die \textit{Clock}-Funktionalität von X10. Eine Clock entspricht einer Barriere, die alle Aktiväten bei Erreichen so lange blockiert, bis alle registrierten Aktivitäten die Barriere erreicht haben. Es wird sowohl für alle Aktivitäten (es gibt eine Aktivität pro PE) global eine Clock benötigt, als auch lokal zwischen je allen Aktivitäten auf dem selben Place eine Clock benötigt. Um diese Clocks zu erstellen, ist es nötig den Infect-Aufruf manuell zweistufig zu implementieren. Zunächst wird eine Clock erstellt, dann wird eine Aktivität pro involviertem Place gestartet, die sich aber nicht in der Clock registrieren. Anschließend wird von der einen Aktivität auf jedem Place eine weitere Clock erstellt und pro PE, die auf diesem Place zur Verfügung steht eine Aktivität gestartet. Diese Aktivität registriert sich jetzt in beiden oben erstellten Clocks und beginnt mit der BFS.

Ein weiterer Vorteil des zweistufigen Infects ist es, dass sehr einfach jeder Aktivität ein globaler Index und ein lokaler Index gegeben werden kann. Vor allem der lokale Index wird im weiteren sehr nützlich sein.
% subsubsection zweistufiges_infect (end)

\subsubsection{Lokale Parallelität} % (fold)
\label{ssub:lokale_parallelit_t}
Wie die Kollaboration zwischen den einzelnen Places aussieht wurde bereits in Kapitel \ref{sec:1d_partitionierung} beschrieben. Ein Place als ganzes Verhält sich im invasiven Fall exakt gleich. Allerdings gibt es keine \enquote{Masteaktivity} pro Place, die Jobs verteilen kann und für die Synchronisation sorgt. Stattdessen werden mehrere gleichberechtigte Activities gestartet, die trotzdem auf den selben Daten arbeiten sollen. In diesem Abschnitt wird beschrieben, wie diese Zusammenarbeit gelöst wurde. Dazu werden die Phasen aus Kapitel \ref{sec:1d_partitionierung} aufgegriffen. Eine genaue Beschreibung der einzelnen Phasen findet sich auch dort und wird hier nicht wiederholt. Wichtig ist, dass jede Aktivity die Information hat, die wievielte von wievielen sie auf diesem Place ist.

\subsection{Phase 1: Adjazente Knoten sortieren} % (fold)
\label{sub:phase_1_invasive}
Die Liste der aktiven Knoten ist einmal pro Place vorhanden. Sie ist als Arrayliste implementiert und ermöglicht somit schnellen Zugriff auf beliebige Elemente. In Phase 1 wird die Liste in gleichgroße Stücke aufgeteilt, so dass jede Acitivty auf dem Place ein Stück bekommt. Es steht pro Zielplace aber nur ein Sendpuffer zur Verfügung, in den alle konkurrierend schreiben. Deswegen muss sichergestellt werden, dass der Zugriff auf jeden Buffer atomar passiert. Nach dieser Phase ist lediglich eine lokale Barriere nötig um sicherzustellen, dass alle Sendepuffer korrekt und vollständig geschrieben wurden. 
% subsection phase_1 (end)

\subsection{Phase 2: Kommunikation} % (fold)
\label{sub:parallel_phase_2_invasive}
In Phase 2 werden die Sendepuffer gesendet. Eine Aktivität ist für einen Sendepuffer genau dann zuständig, wenn die id des Ziels modulo der Anzahl an Activities auf diesem Place der lokalen id dieser Aktivität entspricht. Ansonsten ist hier nichts anzupassen. Nach dem Senden wird eine globale Barriere benötigt, damit alle Empfangspuffer korrekt geschrieben wurden, bevor diese ausgewertet werden.
% subsection phase_2 (end)

\subsection{Phase 3: BFS-Distanz aktualisieren} % (fold)
\label{sub:phase_3_invasive}
Wie in Phase 2 liest eine Activity genau dann einen Empfangspuffer, wenn die id des Senders modulo Anzahl an Activities auf diesem Place die lokale id der Actitivy ergibt. 
% subsection phase_3 (end)

% subsubsection lokale_parallelit_t (end)
\subsubsection{Allreduce} % (fold)
\label{ssub:allreduce_invasive}
Das Allreduce ist im invasiven Fall insofern nichtmehr nötig, als dass es keine All-to-All Operation mehr ist. Es wird ohnehin nach jeder BFS-Iteration zunächst die Berechnung gestoppt und nur falls eine weitere Iteration nötig ist erneut ein \textit{infect} aufgerufen. Das Ergebnis der aktuellen Iteration schreiben alle Acivities in ein Array, das Anfangs erstellt wird und dass eine Zelle für jede Acitivy bereithält. Um das Array zu adressieren, wird jeder Activit eine GlobalRef übergeben. Die Master-Activity reduziert dieses Array dann lokal.
% subsubsection allreduce (end)
% subsection ablauf_des_algorithmus (end)
% section der_algorithmus (end)	


% chapter breitensuche_im_invasiven_kontext (end)